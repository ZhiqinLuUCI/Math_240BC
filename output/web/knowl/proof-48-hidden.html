<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-07-25T14:03:48-07:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math"><article class="hiddenproof"><p>Since <span class="process-math">\(w\)</span> is a smooth function vanishes on the boundary, it can be viewed as the defining function of <span class="process-math">\(\Omega\text{.}\)</span> By the implicit function theorem, we solve the equation</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
w(x_1, \cdots, x_n) = 0
\end{equation*}
</div>
<p class="continuation">to get the function</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
x_n = x_n(x_1, \cdots, x_{n-1})\text{.}
\end{equation*}
</div>
<p>If <span class="process-math">\(\Omega\)</span> is convex, then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{\partial^2 x_n}{\partial x_i \partial x_j} &gt; 0\text{,}
\end{equation*}
</div>
<p class="continuation">is a positive definite matrix. Using the chain rule, the above inequality is equivalent to</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-\frac{w_{ij}}{w_n} + \frac{w_{in} w_j}{w_n^2} + \frac{w_{jn} w_i}{w_n^2} -\frac{w_i w_j w_{nn}}{w_n^3} &gt; 0\text{.}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(1\leqslant i, j \leqslant n-1\text{.}\)</span> However, if we allow <span class="process-math">\(i\)</span> or <span class="process-math">\(j\)</span> to be <span class="process-math">\(n\text{,}\)</span> then as the <span class="process-math">\(n\times n\)</span> matrix, we still have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-\frac{w_{ij}}{w_n} + \frac{w_{in}w_j}{w_n^2} + \frac{w_{jn}w_i}{w_n^2} -\frac{w_i w_j w_{nn}}{w_n^3} \geqslant 0\text{.}
\end{equation*}
</div>
<p>Moreover, for any <span class="process-math">\((a_1, \cdots, a_n)\text{,}\)</span> if <span class="process-math">\(\sum a_j w_j = 0\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-w_{ij} a_i a_j \geqslant \varepsilon |a|^2
\end{equation*}
</div>
<p class="continuation">for some positive <span class="process-math">\(\varepsilon &gt; 0\text{.}\)</span> A generic vector has the form <span class="process-math">\(a+\mu b\text{,}\)</span> where <span class="process-math">\(b = (w_1, \cdots, w_n)\text{.}\)</span> For <span class="process-math">\(w\)</span> small enough, we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
-w_{ij}(a_i + \mu b_i)(a_j + \mu b_j) + \frac{1}{w} |\mu|^2 |b|^4 &gt; 0\text{.}
\end{equation*}
</div>
<p>Thus <span class="process-math">\(\nabla^2\log w\text{,}\)</span> whose matrix entries are</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\frac{w_{ij}}{w} - \frac{w_i w_j}{w^2}\text{,}
\end{equation*}
</div>
<p class="continuation">is negative definite for <span class="process-math">\(w\)</span> small enough.</p></article></body>
</html>
